{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'cutorch'\n",
    "require 'nn'\n",
    "require 'cunn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- load data file\n",
    "dataFile = '../data/hh.t7'\n",
    "hh = torch.load(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processing training pair 10\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 20\t\n",
       "processing training pair 30\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 40\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 50\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 60\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 70\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 80\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 90\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 100\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 110\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 120\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 130\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 140\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 150\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 160\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 170\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 180\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 190\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "processing training pair 200\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : DoubleTensor - size: 418x1x240x320\n",
       "  labels : DoubleTensor - size: 418\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = {}\n",
    "train_pos = hh.train.labels:nonzero()\n",
    "train_neg = torch.add(hh.train.labels,-1):nonzero()\n",
    "\n",
    "-- create training set with every other example a negative\n",
    "neg_stride = math.floor(train_neg:size(1) / train_pos:size(1))\n",
    "numTrainPairs = train_pos:size(1)\n",
    "numTrainExamples = numTrainPairs*2\n",
    "trainData = torch.Tensor(numTrainExamples,1,240,320)\n",
    "trainLabels = torch.Tensor(numTrainExamples)\n",
    "for i = 1,numTrainPairs do\n",
    "    if i % 10 == 0 then\n",
    "        print('processing training pair ' .. i)\n",
    "    end\n",
    "\n",
    "    local pos_idx = train_pos[i]\n",
    "    local neg_idx = train_neg[(i-1)*neg_stride+1]\n",
    "\n",
    "    trainData[2*i-1] = hh.train.data:narrow(1,pos_idx[1],1):float()\n",
    "    trainLabels[2*i-1] = hh.train.labels:narrow(1,pos_idx[1],1) + 1\n",
    "\n",
    "    trainData[2*i] = hh.train.data:narrow(1,neg_idx[1],1):float()\n",
    "    trainLabels[2*i] = hh.train.labels:narrow(1,neg_idx[1],1) + 1\n",
    "end\n",
    "\n",
    "trainset.data = trainData\n",
    "trainset.labels = trainLabels\n",
    "\n",
    "print(trainset)\n",
    "    \n",
    "testset = hh.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.labels[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end\n",
    "\n",
    "setmetatable(testset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.labels[i]} \n",
    "                end}\n",
    ");\n",
    "testset.data = testset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function testset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 0.21585217551476\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 0.069773298737423\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,1 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "\n",
    "-- view an image\n",
    "-- itorch.image(trainset.data[301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- define network\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 7, 7, 2, 2))\n",
    "net:add(nn.SpatialMaxPooling(3,3,3,3))  \n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5, 2, 2))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "-- net:add(nn.SpatialConvolution(16, 16, 5, 5))\n",
    "-- net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net = net:cuda()\n",
    "-- out = net:forward(trainset.data[1]) -- must cuda the data first\n",
    "-- print(out:size())\n",
    "    \n",
    "net:add(nn.View(16*9*12))                   \n",
    "net:add(nn.Linear(16*9*12, 50))            \n",
    "net:add(nn.Linear(50, 2)) \n",
    "--net:add(nn.Linear(120, 84))\n",
    "--net:add(nn.Linear(84, 2))                  \n",
    "net:add(nn.LogSoftMax())                    \n",
    "\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.49706102921917\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.36690123464787\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.3006043794908\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.24953644918768\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.20974730454278\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.17740567042782\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.1506308439103\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.1301967649939\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.11524672014862\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.10315171069506\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.10315171069506\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--train\n",
    "net = net:cuda()\n",
    "criterion = criterion:cuda()\n",
    "trainset.data = trainset.data:cuda()\n",
    "\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 10\n",
    "\n",
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3149\t61.324245374878 % \t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- test accuracy\n",
    "\n",
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,1 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "testset.data = testset.data:cuda()\n",
    "\n",
    "testSize = #testset.data\n",
    "numTestExamples = testSize[1]\n",
    "correct = 0\n",
    "for i=1,numTestExamples do\n",
    "    local groundtruth = testset.labels[i] + 1\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "print(correct, 100*correct/numTestExamples .. ' % ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy 1,56.531845653185 %\t\n",
       "accuracy 2,86.074429771909 %\t\n",
       "{\n",
       "  1 : 2548\n",
       "  2 : 2587\n",
       "}\n",
       "{\n",
       "  1 : 2432\n",
       "  2 : 717\n",
       "}\n",
       "{\n",
       "  1 : 4302\n",
       "  2 : 833\n",
       "}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- test accuracy by class\n",
    "\n",
    "class_preds = {0, 0}\n",
    "class_performance = {0, 0}\n",
    "class_counts = {0, 0}\n",
    "for i=1,numTestExamples do\n",
    "    local groundtruth = testset.labels[i] + 1\n",
    "    class_counts[groundtruth] = class_counts[groundtruth] + 1\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    class_preds[indices[1]] = class_preds[indices[1]] + 1\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "for i=1,2 do\n",
    "    print('accuracy ' .. i .. ',' .. 100*class_performance[i]/class_counts[i] .. ' %')\n",
    "end\n",
    "\n",
    "print(class_preds)\n",
    "print(class_performance)\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408\t97.607655502392 % \t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- train accuracy\n",
    "\n",
    "trainSize = #trainset.data\n",
    "numTrainExamples = trainSize[1]\n",
    "correct = 0\n",
    "for i=1,numTrainExamples do\n",
    "    local groundtruth = trainset.labels[i]\n",
    "    local prediction = net:forward(trainset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "print(correct, 100*correct/numTrainExamples .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy 1,96.172248803828 %\t\n",
       "accuracy 2,99.043062200957 %\t\n",
       "{\n",
       "  1 : 203\n",
       "  2 : 215\n",
       "}\n",
       "{\n",
       "  1 : 201\n",
       "  2 : 207\n",
       "}\n",
       "{\n",
       "  1 : 209\n",
       "  2 : 209\n",
       "}\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- train accuracy by class\n",
    "\n",
    "class_performance = {0, 0}\n",
    "class_counts = {0, 0}\n",
    "class_preds = {0,0}\n",
    "for i=1,trainset:size() do\n",
    "    local groundtruth = trainset.labels[i]\n",
    "    class_counts[groundtruth] = class_counts[groundtruth] + 1\n",
    "    local prediction = net:forward(trainset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    class_preds[indices[1]] = class_preds[indices[1]] + 1\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "for i=1,2 do\n",
    "    print('accuracy ' .. i .. ',' .. 100*class_performance[i]/class_counts[i] .. ' %')\n",
    "end\n",
    "print(class_preds)\n",
    "print(class_performance)\n",
    "print(class_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
